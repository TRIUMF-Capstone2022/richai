# Appendix C: XGBoost

(appendix:ml_gbm:intro)=
## C.1: Why is XGBoost a good baseline model?

XGBoost uses an ensemble of decision trees sequentially minimizing a loss function and hence are popular due their efficiency, accuracy and ability to avoid overfitting. Besides, the libraries associated offer flexibility in terms of parameters such as decision tree algorithm, loss function, regularization, GPU related parameters etc. which make them a popular first choice as baseline models.
